#!/usr/bin/env python3
"""
æ‰¹é‡æµ‹è¯•è„šæœ¬
åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
"""

import argparse
import json
from pathlib import Path
import torch
import numpy as np
from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

from train_chord_stft import ChordCNN, ChordDataset, LabelExtractor
from train_chord_cqt import ChordDatasetCQT


def evaluate_model(model, test_loader, device, idx_to_label):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    
    all_predictions = []
    all_labels = []
    all_confidences = []
    
    with torch.no_grad():
        for inputs, labels in tqdm(test_loader, desc='Testing'):
            inputs, labels = inputs.to(device), labels.to(device)
            
            outputs = model(inputs)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            confidences, predictions = probabilities.max(1)
            
            all_predictions.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_confidences.extend(confidences.cpu().numpy())
    
    return np.array(all_predictions), np.array(all_labels), np.array(all_confidences)


def plot_confusion_matrix(y_true, y_pred, labels, save_path, title='Confusion Matrix'):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
    cm = confusion_matrix(y_true, y_pred)
    # è®¡ç®—ç™¾åˆ†æ¯”
    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100
    n = len(labels)
    # æ¯ä¸ªç±»åˆ«åˆ†é…0.7è‹±å¯¸ï¼Œæœ€å°12ï¼Œæœ€å¤§40
    size = min(max(n * 0.7, 12), 40)
    plt.figure(figsize=(size, size * 0.8))
    sns.heatmap(
        cm_percent,
        annot=True,
        fmt='.1f',
        cmap='Blues',
        xticklabels=labels,
        yticklabels=labels,
        cbar_kws={'label': 'Percentage (%)'}
    )
    plt.title(title)
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"æ··æ·†çŸ©é˜µä¿å­˜åˆ°: {save_path}")


def plot_confidence_distribution(confidences, predictions, labels, correct_mask, save_path):
    """ç»˜åˆ¶ç½®ä¿¡åº¦åˆ†å¸ƒ"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    # æ­£ç¡® vs é”™è¯¯é¢„æµ‹çš„ç½®ä¿¡åº¦
    correct_conf = confidences[correct_mask]
    wrong_conf = confidences[~correct_mask]
    
    ax1.hist(correct_conf, bins=50, alpha=0.7, label='Correct', color='green')
    ax1.hist(wrong_conf, bins=50, alpha=0.7, label='Wrong', color='red')
    ax1.set_xlabel('Confidence')
    ax1.set_ylabel('Count')
    ax1.set_title('Confidence Distribution: Correct vs Wrong')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # æ¯ä¸ªç±»åˆ«çš„å¹³å‡ç½®ä¿¡åº¦
    unique_labels = np.unique(predictions)
    avg_confidences = [confidences[predictions == label].mean() for label in unique_labels]
    label_names = [labels[label] for label in unique_labels]
    
    ax2.bar(range(len(unique_labels)), avg_confidences)
    ax2.set_xlabel('Class')
    ax2.set_ylabel('Average Confidence')
    ax2.set_title('Average Confidence by Class')
    ax2.set_xticks(range(len(unique_labels)))
    ax2.set_xticklabels(label_names, rotation=45, ha='right')
    ax2.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ç½®ä¿¡åº¦åˆ†å¸ƒå›¾ä¿å­˜åˆ°: {save_path}")


def main():
    parser = argparse.ArgumentParser(description='æ‰¹é‡æµ‹è¯•å’Œå¼¦è¯†åˆ«æ¨¡å‹ï¼ˆæ”¯æŒ STFT å’Œ CQTï¼‰')
    parser.add_argument('--data_dir', type=str, required=True,
                        help='æµ‹è¯•æ•°æ®ç›®å½•')
    parser.add_argument('--model', type=str, required=True,
                        help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--mappings', type=str, required=True,
                        help='æ ‡ç­¾æ˜ å°„æ–‡ä»¶')
    parser.add_argument('--batch_size', type=int, default=32,
                        help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--device', type=str, default='cuda',
                        help='è®¾å¤‡: cuda, mps æˆ– cpu')
    parser.add_argument('--output_dir', type=str, default='test_results'+'_undefined',
                        help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)
    
    # æ£€æµ‹è®¾å¤‡
    if args.device == 'cuda' and torch.cuda.is_available():
        device = 'cuda'
    elif args.device == 'mps' and torch.backends.mps.is_available():
        device = 'mps'
    else:
        device = 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}\n")
    
    # åŠ è½½æ ‡ç­¾æ˜ å°„
    with open(args.mappings, 'r') as f:
        mapping_data = json.load(f)
    
    task = mapping_data['task']
    num_classes = mapping_data['num_classes']
    label_mappings = mapping_data['mappings']
    
    # æ£€æµ‹æ¨¡å‹ç±»å‹ï¼ˆSTFT æˆ– CQTï¼‰
    model_type = 'cqt' if 'n_bins' in mapping_data else 'stft'
    n_bins = mapping_data.get('n_bins', 84)
    bins_per_octave = mapping_data.get('bins_per_octave', 12)
    
    print(f"æ¨¡å‹ç±»å‹: {model_type.upper()}")
    if model_type == 'cqt':
        print(f"CQT å‚æ•°: n_bins={n_bins}, bins_per_octave={bins_per_octave}")
    print()
    
    # æ„å»ºå®Œæ•´çš„æ˜ å°„ï¼ˆåŒ…æ‹¬åå‘æ˜ å°„ï¼Œç›´æ¥ç”¨å­—ç¬¦ä¸²æ ‡ç­¾ï¼Œä¸åšä»»ä½•æ˜ å°„ï¼‰
    full_mappings = label_mappings.copy()
    if task == 'full':
        idx_to_label = {v: k for k, v in label_mappings['full_label_to_idx'].items()}
    elif task == 'root':
        idx_to_label = {v: k for k, v in label_mappings['root_to_idx'].items()}
    else:
        idx_to_label = {v: k for k, v in label_mappings['chord_to_idx'].items()}
    
    print(f"ä»»åŠ¡ç±»å‹: {task}")
    print(f"ç±»åˆ«æ•°: {num_classes}\n")
    
    # åˆ›å»ºæ•°æ®é›†ï¼ˆæ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ï¼‰
    print("åŠ è½½æµ‹è¯•æ•°æ®...")
    if model_type == 'cqt':
        dataset = ChordDatasetCQT(
            wav_dir=args.data_dir,
            label_mappings=full_mappings,
            task=task,
            n_bins=n_bins,
            bins_per_octave=bins_per_octave
        )
    else:
        dataset = ChordDataset(
            wav_dir=args.data_dir,
            label_mappings=full_mappings,
            task=task
        )
    
    test_loader = torch.utils.data.DataLoader(
        dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4
    )
    
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(dataset)}\n")
    
    # åŠ è½½æ¨¡å‹
    print("åŠ è½½æ¨¡å‹...")
    model = ChordCNN(num_classes=num_classes)
    checkpoint = torch.load(args.model, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    
    print(f"æ¨¡å‹è®­ç»ƒè½®æ•°: {checkpoint['epoch'] + 1}")
    print(f"éªŒè¯å‡†ç¡®ç‡: {checkpoint['val_acc']:.2f}%\n")
    
    # è¯„ä¼°
    print("="*60)
    print("å¼€å§‹è¯„ä¼°")
    print("="*60 + "\n")
    
    predictions, true_labels, confidences = evaluate_model(
        model, test_loader, device, idx_to_label
    )
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = (predictions == true_labels).mean() * 100
    correct_mask = predictions == true_labels
    
    print(f"\næ€»ä½“å‡†ç¡®ç‡: {accuracy:.2f}%")
    print(f"å¹³å‡ç½®ä¿¡åº¦: {confidences.mean()*100:.2f}%")
    print(f"æ­£ç¡®é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {confidences[correct_mask].mean()*100:.2f}%")
    print(f"é”™è¯¯é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {confidences[~correct_mask].mean()*100:.2f}%\n")
    
    # åˆ†ç±»æŠ¥å‘Š
    label_names = [idx_to_label[i] for i in range(num_classes)]
    report = classification_report(
        true_labels,
        predictions,
        target_names=label_names,
        digits=4
    )
    
    print("="*60)
    print("è¯¦ç»†åˆ†ç±»æŠ¥å‘Š")
    print("="*60)
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = output_dir / f'classification_report_{task}.txt'
    with open(report_path, 'w') as f:
        f.write(f"Task: {task}\n")
        f.write(f"Model: {args.model}\n")
        f.write(f"Test Accuracy: {accuracy:.2f}%\n\n")
        f.write(report)
    
    print(f"\næŠ¥å‘Šä¿å­˜åˆ°: {report_path}")
    
    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    cm_path = output_dir / f'confusion_matrix_{task}.png'
    plot_confusion_matrix(
        true_labels,
        predictions,
        label_names,
        cm_path,
        title=f'Confusion Matrix - {task.capitalize()} Task'
    )
    
    # ç»˜åˆ¶ç½®ä¿¡åº¦åˆ†å¸ƒ
    conf_path = output_dir / f'confidence_distribution_{task}.png'
    plot_confidence_distribution(
        confidences,
        predictions,
        label_names,
        correct_mask,
        conf_path
    )
    
    # ä¿å­˜é”™è¯¯æ ·æœ¬
    print("\nåˆ†æé”™è¯¯æ ·æœ¬...")
    wav_files = sorted(list(Path(args.data_dir).glob('*.wav')))
    errors = []
    
    for i, (pred, true, conf) in enumerate(zip(predictions, true_labels, confidences)):
        if pred != true:
            errors.append({
                'file': wav_files[i].name,
                'true_label': idx_to_label[true],
                'predicted_label': idx_to_label[pred],
                'confidence': f"{conf*100:.2f}%"
            })
    
    if errors:
        error_path = output_dir / f'error_samples_{task}.json'
        with open(error_path, 'w') as f:
            json.dump(errors, f, indent=2)
        
        print(f"é”™è¯¯æ ·æœ¬æ•°: {len(errors)}")
        print(f"é”™è¯¯æ ·æœ¬ä¿å­˜åˆ°: {error_path}")
        
        # æ‰“å°å‰ 10 ä¸ªé”™è¯¯
        print("\nå‰ 10 ä¸ªé”™è¯¯æ ·æœ¬:")
        print("-" * 80)
        for error in errors[:10]:
            print(f"æ–‡ä»¶: {error['file']}")
            print(f"  çœŸå®: {error['true_label']} | é¢„æµ‹: {error['predicted_label']} | ç½®ä¿¡åº¦: {error['confidence']}")
    else:
        print("ğŸ‰ å®Œç¾ï¼æ²¡æœ‰é”™è¯¯æ ·æœ¬ï¼")
    
    print("\n" + "="*60)
    print(f"æµ‹è¯•å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")
    print("="*60)


if __name__ == '__main__':
    # é»˜è®¤è°ƒç”¨æœ€æ–°æ¨¡å‹å’Œæ ‡ç­¾æ˜ å°„
    import glob
    import os
    import sys
    
    # ä¼˜å…ˆæŸ¥æ‰¾ CQT æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ STFT æ¨¡å‹
    cqt_model_dir = 'models_full_cqt'
    stft_model_dir = 'models_full_stft'
    
    # æŸ¥æ‰¾ CQT æ¨¡å‹
    cqt_model_files = sorted(glob.glob(os.path.join(cqt_model_dir, 'chord_model_full_*.pth'))) if os.path.exists(cqt_model_dir) else []
    cqt_mapping_files = sorted(glob.glob(os.path.join(cqt_model_dir, 'label_mappings_full_*.json'))) if os.path.exists(cqt_model_dir) else []
    
    # æŸ¥æ‰¾ STFT æ¨¡å‹
    stft_model_files = sorted(glob.glob(os.path.join(stft_model_dir, 'chord_model_full_*.pth'))) if os.path.exists(stft_model_dir) else []
    stft_mapping_files = sorted(glob.glob(os.path.join(stft_model_dir, 'label_mappings_full_*.json'))) if os.path.exists(stft_model_dir) else []
    
    if cqt_model_files and cqt_mapping_files:
        # ä½¿ç”¨ CQT æ¨¡å‹
        latest_model = cqt_model_files[-1]
        latest_mapping = cqt_mapping_files[-1]
        output_dir = 'test_results_cqt'
        print(f"æ‰¾åˆ° CQT æ¨¡å‹: {latest_model}")
    elif stft_model_files and stft_mapping_files:
        # ä½¿ç”¨ STFT æ¨¡å‹
        latest_model = stft_model_files[-1]
        latest_mapping = stft_mapping_files[-1]
        output_dir = 'test_results_stft'
        print(f"æ‰¾åˆ° STFT æ¨¡å‹: {latest_model}")
    else:
        print("é”™è¯¯: æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")
        sys.exit(1)
    
    if len(sys.argv) == 1:  # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼
        sys.argv += [
            '--data_dir', 'single_chords_output',
            '--model', latest_model,
            '--mappings', latest_mapping,
            '--output_dir', output_dir,
            '--device', 'mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu')
        ]
    main()
